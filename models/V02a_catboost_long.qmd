---
title: "Xgboost Modeling Long 41 days. classification with thirdile returns. V02a"
format: 
  html: 
    toc: true
    toc-depth: 2
    toc-location: left
    theme: darkly
    fontsize: 1.1em
    grid: 
      sidebar-width: 0px
      body-width: 2000px
      margin-width: 0px
---

TODO
Check correlation
check correlation: roll_sd_intraday_3M, roll_sd_ret1d_63days.  I would imagine they are very similar.
add ATR (2 different ones, 11 days, 19 days) ... put it as a percentage.  
Put something about volume weighted average 


# Intro 

This model built on V1.  It removes the 5 least important variables and add a bunch of new ones.  It also add lagging values of the 5 most important ones. 

* This is a classification model.  Forward returns have been ordered in thirdile. 
* The model engine is Xgboost  
* To predict: Forward return at 41 days and 61 days.  

Other idiosyncrasies of this model: 

* all returns are log returns

Changes from V01 
* We are using V01 and introducing 3 lags for each of the top 5 variables (lag5, lag11, lag19).  
* We are removing the bottom 5 variables from V01
  + corr_sma50_sma200_1Y, above_sd_ret5d_3M, above_sd_ret5d_7M, above_sd_intraday_1Y, above_sd_ret1d_3M
* We use returns but are scaling the returns in the pre-processing stage. 
* we are adding percentage above main moving average (EMA23, SMA47, SMA101, SMA199)

# Pre-processing 

## Setting up 

```{r}
#| label: setup
#| message: false
#| warning: false
#| eval: true

library(dplyr)
library(purrr)
library(readr)
library(lubridate)
library(tidyr)
library(glue)

the_path <- here::here()

ticker <- 'RIO'
num_days <- '41d'

yop <- glue('catboost_v02a_', num_days, "_", ticker)
```

## Buidling df 

```{r}
#| label: building-df
#| message: false
#| warning: false

library(timetk)

sd_roll_31d <- slidify(.f = sd, .align = 'right', .period = 31)
mean_roll_61d <- slidify(.f = mean, .align = 'right', .period = 61)
sd_roll_61d <- slidify(.f = sd, .align = 'right', .period = 61)
sd_roll_63d <- slidify(.f = sd, .align = 'right', .period = 63)
mean_roll_147d <- slidify(.f = mean, .align = 'right', .period = 147)
sd_roll_147d <- slidify(.f = sd, .align = 'right', .period = 147)
mean_roll_251d <- slidify(.f = mean, .align = 'right', .period = 251)
sd_roll_251d <- slidify(.f = sd, .align = 'right', .period = 251)
corr_roll_101d <- slidify(.f = ~cor(.x, .y), .align = 'right', .period = 101)
corr_roll_199d <- slidify(.f = ~cor(.x, .y), .align = 'right', .period = 199)
corr_roll_229d <- slidify(.f = ~cor(.x, .y), .align = 'right', .period = 229)
corr_roll_251d <- slidify(.f = ~cor(.x, .y), .align = 'right', .period = 251)

df <- read_csv(glue(the_path, '/data_stock_fmpr/', ticker, '.csv')) |> 
  arrange(date) |> 
  select(date, open, high, low, close, volume)
yo <- tibble(atr11 = TTR::ATR(df[, 3:5], n = 11)[,2])
df <- bind_cols(df, yo) |> mutate(atr11_open = atr11/open) |> select(-atr11)
yo <- tibble(atr17 = TTR::ATR(df[, 3:5], n = 17)[,2]) 
df <- bind_cols(df, yo) |> mutate(atr17_open = atr17/open) |> select(-atr17)

df <- df |> 
  mutate(ret_1d = log(close / lag(close, n = 1)), 
         ret_5d = log(close / lag(close, n = 5)), 
         ret_21d = log(close / lag(close, 21)), 
         
         roll_sd_ret1d_61d = sd_roll_61d(ret_1d), 
         roll_mean_ret1d_61d = mean_roll_61d(ret_1d), 
         roll_sd_ret1d_147d = sd_roll_147d(ret_1d), 
         roll_mean_ret5d_61d = mean_roll_61d(ret_5d), 
         roll_sd_ret5d_61d = sd_roll_61d(ret_5d), 
         roll_mean_ret5d_147d = mean_roll_147d(ret_5d), 
         roll_sd_ret5d_147d = sd_roll_147d(ret_5d), 
         roll_sd_ret5d_147d_lag5 = lag(roll_sd_ret5d_147d, n = 5), 
         roll_sd_ret5d_147d_lag11 = lag(roll_sd_ret5d_147d, n = 11), 
         corr_rollSdRet5d3M_rollSdRet5d7M_229d = corr_roll_229d(roll_sd_ret5d_61d, roll_sd_ret5d_147d), 
         roll_sd_ret21d_251d = sd_roll_251d(ret_21d),     
         roll_sd_ret21d_251d_lag7 = lag(roll_sd_ret21d_251d, n = 7), 
         roll_sd_ret21d_251d_lag19 = lag(roll_sd_ret21d_251d, n = 19),
         
         intraday = (high - low) / open, 
         roll_sd_intraday_61d = sd_roll_61d(intraday), 
         roll_sd_intraday_251d = sd_roll_251d(intraday), 
         
         ## old parameters
         ema20 = TTR::EMA(close, 20), 
         sma50 = TTR::SMA(close, 50), 
         sma101 = TTR::SMA(close, 101), 
         sma199 = TTR::SMA(close, 199),
         roll_mean_sma199_251d = mean_roll_251d(sma199), 
         roll_sd_sma199_251d = sd_roll_251d(sma199), 
         above_sd_sma199_251d = (sma199 - roll_mean_sma199_251d) / roll_sd_sma199_251d, 
         sma200 = TTR::SMA(close, 200),
         ma_cross_l = sma50 / sma101, 
         corr_ema20_sma50_199d = corr_roll_199d(ema20, sma50), 
         corr_ema20_sma50_251d = corr_roll_251d(ema20, sma50), 
         corr_sma50_sma200_101d = corr_roll_101d(sma50, sma200), 
         corr_sma50_sma200_199d = corr_roll_199d(sma50, sma200), 
         
         volum_sma200 = TTR::SMA(volume,  n = 200), 
         volum200_perc = log(volume / volum_sma200), 
         roll_sd_volu200_31d = sd_roll_31d(volum200_perc), 
         roll_sd_volu200_251d = sd_roll_251d(volum200_perc), 
         roll_sd_volu200_251d_lag5 = lag(roll_sd_volu200_251d, n = 5), 
         roll_sd_volu200_251d_lag17 = lag(roll_sd_volu200_251d, n = 17), 
         
         forw_ret = log(lead(close, n = parse_number(num_days)) / close), 
         ord_class = as.factor(ntile(forw_ret, 3)))

df2 <- df |> 
  select(date, atr11_open, atr17_open, 
         roll_mean_ret1d_61d, roll_mean_ret5d_61d, roll_mean_ret5d_147d, 
         roll_sd_ret1d_61d, roll_sd_ret1d_147d, roll_sd_ret5d_147d, 
         roll_sd_ret5d_147d_lag5, roll_sd_ret5d_147d_lag11, 
         corr_rollSdRet5d3M_rollSdRet5d7M_229d, 
         roll_sd_ret21d_251d, roll_sd_intraday_61d, roll_sd_intraday_251d, 
         roll_sd_ret21d_251d_lag7, roll_sd_ret21d_251d_lag19, 
         above_sd_sma199_251d, 
         ma_cross_l, 
         corr_ema20_sma50_199d, corr_ema20_sma50_251d, 
         corr_sma50_sma200_199d, corr_sma50_sma200_101d,
         roll_sd_volu200_31d, roll_sd_volu200_251d, 
         roll_sd_volu200_251d_lag5, roll_sd_volu200_251d_lag17, 
         ord_class) 

df_model <- df2 
df_new2 <- df_model |> filter(date > '2023-06-30')
df_model <- df_model |> filter(date < '2023-06-30') |> drop_na()
```

## Resampling and Recipes 

```{python}
import pandas as pd
import numpy as np
df_cb = yoo
df_cb.isnull().sum()
X = df_cb.drop(['date', 'ord_class'], axis = 1)
X.values
y = df_cb['ord_class']

from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score, f1_score, recall_score
from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay


tscv = TimeSeriesSplit(n_splits = 5, gap=40)

model_cb_basics = CatBoostClassifier(iterations = 800, depth = 12, learning_rate = 0.0001, loss_function='MultiClass', verbose = True)

model_cb_basics.fit(X, y)
model_cb_basics.predict_proba(X)

accuracy_score(y, model_cb_basics.predict(X))
df_new = r.df_new2
#df_new.dropna(inplace=True)
df_new3 = df_new.drop(['date', 'ord_class'], axis = 1, inplace = False)
#y_new = df_new['ord_class']

#accuracy_score(y_new, model_cb_basics.predict(df_new3))
#f1_score(y_new, model_cb_basics.predict(df_new3), average = 'macro')
yo = model_cb_basics.predict(df_new3)
data = [[y_new], [yo[:,0]]]
yo = pd.DataFrame(data, columns = ['ord_class', 'predictions'])
```

```{r}
df_cb_pred <- tibble(ord_class = df_new2$ord_class,  predictions = py$yo)
yooo <- py$yo
```

```{python}
#| label: py_catboost_tuned
#| message: true

import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from catboost import CatBoostClassifier

df_cb = r.df_model

X = df_cb.drop(['date', 'ord_class'], axis = 1) 
y = df_cb['ord_class']

tscv = TimeSeriesSplit(n_splits = 5, gap=40)

model_cb_hp = CatBoostClassifier(loss_function='MultiClass', verbose = True)
param_grid = {'iterations': [550, 650, 750, 850], 
              'learning_rate': [0.001, 0.003, 0.007, 0.01, 0.0005], 
              'depth': [7, 9, 11, 13]}
rs = RandomizedSearchCV(model_cb_hp, param_grid, cv = tscv, n_jobs = 3)

rs.fit(X, y)

model_cb_hp_bestParam = CatBoostClassifier(**rs.best_params_)
model_cb_hp_fitted = model_cb_hp_bestParam.fit(X, y)

import matplotlib.pyplot as plt
feature_imp = model_cb_hp_fitted.feature_importances_
sorted_idx = np.argsort(feature_imp)
fig = plt.figure(figsize=(12, 6))
plt.barh(range(len(sorted_idx)), feature_imp[sorted_idx], align='center')
plt.yticks(range(len(sorted_idx)), np.array(X.columns)[sorted_idx])
plt.title('Feature Importance')
plt.show()

data = {'features': np.array(X.columns), 'rank': sorted_idx, 'varimp': feature_imp}
varimp_df = pd.DataFrame(data)

import joblib
joblib.dump(model_cb_hp_fitted, 'catboost_v02a_41d_CVX.pkl')

loaded_model = joblib.load('../models/catboost_v02a_41d_CVX.pkl')
```

```{r}
library(reticulate)
varimp = py$yo

yooo = py$varimp_df
readr::write_csv(yooo, 'model_metrics/catboost_v02a_41d_CVX.csv')
```

```{python}
# After you train the model using fit(), save like this - 
model.save_model('model_name')    # extension not required.

# And then, later load - 
from catboost import CatBoostClassifier
model = CatBoostClassifier()      # parameters not required.
model.load_model('model_name')

# Now, try predict().

```


```{r}
#| label: preprocessing
#| message: false
#| warning: false

############# SAMPLING FOR CROSS-VALIDATION ##########################
library(rsample)
min_size_training <- 500
number_of_samples <- 43
skippy <- 90
laggy <- 37
# get the size of the df we are using. 
validation_size <- floor(nrow(df_model) * 0.25 / number_of_samples) + 1
training_size <- nrow(df_model) - (skippy * (number_of_samples - 1)) - (laggy + validation_size) - 49

if (training_size < 500) {
  training_size <- min_size_training
  skippy <- floor((nrow(df_model) - validation_size - laggy - min_size_training) / number_of_samples) 
  training_size <- nrow(df_model) - (skippy * (number_of_samples - 1)) - (laggy + validation_size) - 49
}

time_slices <- rolling_origin(df_model, 
                              initial = training_size, assess = validation_size + laggy, 
                              lag = -laggy, skip = skippy, 
                              cumulative = FALSE)

######################################################################
library(recipes)
recipe_base <- recipe(formula = ord_class ~., data = df_model) |> 
  update_role(date, new_role="ID") 
```


# Modeling 

```{r}
#| label: modeling
#| message: false
#| warning: false

library(parsnip)
library(catsnip)
library(tune)
library(dials)
library(workflows)
library(yardstick)
model_catboost <- boost_tree(trees = tune(), mtry = tune(), 
                             tree_depth = tune(), 
                             learn_rate = tune(), min_n = tune()) |> 
  set_engine("catboost") |>  
  set_mode("classification") 

stopping_grid <- grid_latin_hypercube(trees(range = c(600, 1000)), 
                                      mtry(range = c(12L, 19L)), 
                                      learn_rate(range = c(-4, -3)), 
                                      min_n(range = c(17L, 31L)),   
                                      tree_depth(range = c(9L, 17L)), 
                                      size = 23)

wf <- workflow() |> add_recipe(recipe_base) |> add_model(model_catboost)  

doParallel::registerDoParallel(cores = 3)
catboost_resampling <- tune_grid(wf, time_slices, grid = stopping_grid, 
                                 #metrics = metric_set(accuracy, mn_log_loss), 
                                 control = control_resamples(save_pred = TRUE, 
                                                             save_workflow = TRUE))


```



# Variables importance & Metrics 

```{r}
######################################################################
############# ESTABLISHING METRICS  ##################################
######################################################################

df_pred <- xgboost_resampling |> collect_predictions()
yo_soft_acc <- df_pred |> 
  mutate(soft_acc = case_when(.pred_class=="3" & ord_class == "3" ~ 1, 
                              .pred_class=="2" & ord_class == "2" ~ 1, 
                              .pred_class=="1" & ord_class == "1" ~ 1, 
                              .pred_class=="3" & ord_class == "2" ~ 0.5, 
                              .pred_class=="2" & ord_class == "1" ~ 0.5, 
                              TRUE ~ 0)) |> 
  group_by(.config) |> 
  summarize(mean_soft_acc = mean(soft_acc), 
            mtry = mean(mtry), tree_depth = mean(tree_depth), 
            trees = mean(trees), 
            min_n = mean(min_n), learn_rate = mean(learn_rate))

# if I predict a 3, is it indeed a 3? Higher is better
yo_precision <- df_pred |> 
  mutate(spec_3 = if_else(.pred_class == "3" & ord_class == "3", 1, 0)) |> 
  filter(.pred_class == "3") |> 
  group_by(.config) |> 
  summarize(mean_preci = sum(spec_3)/n())

# if there is a "3" in the actual returns, do I manage to predict it! Higher is better
yo_recall <- xgboost_resampling %>% collect_predictions() |>  
  mutate(sens_3 = if_else(.pred_class == "3" & ord_class == "3", 1, 0)) |> 
  select(-mtry, -min_n, -learn_rate, -loss_reduction, -tree_depth) |> 
  filter(ord_class == "3") |> 
  group_by(.config) |> 
  summarize(mean_recall = sum(sens_3)/n())

# if I predict a 3, is it indeed a 3? Higher is better
yo_soft_preci <- xgboost_resampling |> collect_predictions() |> 
  mutate(spec_3 = case_when(.pred_class=="3" & ord_class == "3" ~ 1, 
                            .pred_class=="3" & ord_class == "2" ~ 0.5, 
                            TRUE ~ 0)) %>% 
  filter(.pred_class == "3") |>  
  group_by(.config) |> 
  summarize(mean_soft_preci = sum(spec_3)/n())

yo_cost3 <- left_join(yo_precision, yo_recall) %>% left_join(., yo_soft_preci) %>% 
  left_join(., yo_soft_acc) %>% 
  mutate(soft_acc_rank = percent_rank(mean_soft_acc), 
         recall_rank = percent_rank(mean_recall), 
         preci_rank = percent_rank(mean_preci), 
         soft_preci_rank = percent_rank(mean_soft_preci), 
         avg_rank =  0.25 * preci_rank + 0.3 * soft_preci_rank + 
                     0.15 * soft_acc_rank + 0.3 * recall_rank)

yo_metric <- left_join(yo_precision, yo_soft_acc) |> left_join(yo_recall) |> 
  left_join(yo_soft_preci) |> left_join(yo_cost3) |> 
  select(.config, avg_rank, mean_preci, mean_soft_preci, mean_recall, mean_soft_acc, 
         mtry, tree_depth, trees, min_n, learn_rate) |> 
  arrange(desc(avg_rank), mean_preci)

#rm(yo_sens, yo_spec, yo_cost3, yo_acc, yo_log, yo_cost_acc)

write_csv(yo_metric, glue(the_path, "/models/model_metrics/", yop, ".csv"))
######################################################################

######################################################################


best_model <- yo_metric$.config[1]

best_param <-xgboost_resampling |> collect_metrics() |> 
  filter(.config == best_model) |> slice_tail()
best_param

final_model <- finalize_model(model_xgboost, best_param)
final_model

final_wf <- workflow() |> add_recipe(recipe_base) |> add_model(final_model)
final_wf

model_base <- fit(object = final_wf, data = df_model)

write_rds(model_base, glue(the_path, "/models/model_raw/", yop, ".rda"))

library(vip)
df_prep <- prep(recipe_base)
var_importance <- final_model %>% 
  set_engine("xgboost", importance = TRUE) %>% 
  fit(ord_class ~ ., data = juice(df_prep) %>% select(-date)) %>%
  vi()

write_csv(var_importance, 
          glue(the_path, "/models/model_vars_imp/", yop, ".csv"))
```


# rsample

```{r}
library(lubridate)
ts_df <- time_slices |> 
  mutate(train = map(splits, training), 
         validation = map(splits, testing)) 

get_start_date <- function(x){ min(x$date) }
get_end_date <- function(x){ max(x$date) }

ts_df_dates <- ts_df |> 
  mutate(start_train_date = as_date(map_dbl(train, get_start_date)), 
         end_train_date = as_date(map_dbl(train, get_end_date)), 
         start_test_date = as_date(map_dbl(validation, get_start_date)), 
         end_test_date = as_date(map_dbl(validation, get_end_date))) |> 
  select(-splits, -train, -validation)

glimpse(ts_df_dates)

```


# Analyses of correlation 

```{r correlation}
#| message: false
#| warning: false


# setting up the path within the project for easier portability of code
the_path <- here::here()

library(corrr)
library(glue)
library(dplyr)
library(purrr)
library(tidyr)

source(glue(the_path, "/models/functions/model_v02a.R"))

model <- 'v02a'
tickers = c('AAPL', 'AMD', 'AXP', 'CVX', 'FDX', 'HAL', 'SBUX') 
create_cor_df <- function(ticker, num_days='41d') { 
  df0 <- model02a(ticker, num_days)
  df <- df0 %>% drop_na()
  df_cor <- df %>% select(-date, -ord_class) 
  yo <- correlate(df_cor) %>% shave() %>% stretch()
  return(yo)
  }

df0 <- tibble(model = model, ticker = tickers) %>% 
  mutate(cor_df = map(ticker, create_cor_df)) %>% 
  unnest()

df1 <- df0 %>% filter(r >= 0.5 | r <= -0.5) |> 
  arrange(desc(abs(r)))

write_csv(df1, glue(the_path, '/models/analysis/model_v02a_corr.csv'))

library(gt)

df1 |> gt()
```


