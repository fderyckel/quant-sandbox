---
title: "V08 - Exploration 4 of for modeling"
author: "FdR"
date: "4-12-2023"
format: 
  html: 
    toc: true
    toc_depth: 2
---

# Intro 

* This is a classification model based on thirdile. 
* The model engine is Xgboost  
* To predict: Forward return at 7 weeks.  

```{r}
#| label: setup
#| message: false
#| warning: false
#| eval: false

library(dplyr)
library(purrr)
library(readr)
library(lubridate)
library(tidyr)
library(glue)

the_path <- here::here()

### Function to harmonize the data. 
### ### This is copied from summary_report_v3
conform_data <- function(ticker){
    df <- read_csv(paste0(the_path, "/data_stock_fmpr/", ticker, ".csv"), 
                   show_col_types = FALSE) |>  
      select(date, open, high, low, close, adjusted=adjClose, volume) |>  
      arrange(date) |> 
      filter(date < today() - 252)
    return(df)
}

ticker <- 'CVX'

```

## Checking on missing values or Zero values 

Checking for missing values and dealing with them. 

```{r mis_val, eval=FALSE}
#| label: missingValues
#| message: false
#| warning: false
#| eval: false

check_for_na <- function(ticker) { 
  df <- conform_data(ticker) %>% 
    select(date, open, high, low, close, adjusted, volume) %>% 
    summarize_all((~ sum(is.na(.))))
  return(df)
}

check_for_zero <- function(ticker) { 
    df <- conform_data(ticker) %>% 
    select(open, high, low, close, adjusted, volume) %>% 
    filter(if_any(everything(.), ~ . == 0))
    if (nrow(df) == 0) { 
      print('No zeros, we are good to go!') 
    } else { 
      return(df) 
    }
  }

## checking for 0 or NA
check_for_na(ticker)
check_for_zero(ticker)

```

## Fixing NA values 

NA values seems to appear mainly in the Volume part of the data. 
Noticing missing values in GILD, VOX and VAW.  You can have several days in a row with NA in volume.  

Solution: 
We are not touching the volume of the ETF.  So we are only interested in the volume of the stock. 
Noticing that when volume is NA, it is because they were no trading.  So we can just remove these days. 

```{r eval=FALSE}
#| label: fixingNaValues
#| message: false
#| warning: false
#| eval: false

the_path = here::here()
yo <- read_csv(paste0(the_path, "/data_stock_fmpr/GILD.csv"))
yo_na <- yo %>% filter(is.na(volume))
yo_no_na <- yo %>% filter(is.na(volume) == FALSE)

create_base_fin_df_v8 <- function(df){
  df <- df %>%  
    select(date, open, high, low, close, adjusted, volume) %>% arrange(date) %>% 
    mutate(open = as.numeric(open), high = as.numeric(high), low = as.numeric(low), 
           close = as.numeric(close), adjusted = as.numeric(adjusted), 
           volume = as.numeric(volume)) %>% filter(is.na(volume) == FALSE)
  
}
```



# Building the basic df 

Create all the variables that will be used in the modeling stage. 

```{r base_df}
#| label: create_df
#| message: false
#| warning: false
#| eval: false

library(roll)
library(timetk)

corr_roll_252 <- slidify(.f = ~cor(.x, .y), .align = 'right', .period = 252)
mean_roll_21 <- slidify(.f = mean, .align = 'right', .period = 21)
mean_roll_200 <- slidify(.f = mean, .align = 'right', .period = 200)
sd_roll_200 <- slidify(.f = sd, .align = 'right', .period = 200)
mean_roll_252 <- slidify(.f = mean, .align = 'right', .period = 252)
sd_roll_252 <- slidify(.f = sd, .align = 'right', .period = 252)

augment_df_fin <- function(df){
  df <- df |>   
    arrange(date) |>  
    mutate(ret21d = log(adjusted / lag(adjusted, n = 21)), 
           ema11 = TTR::EMA(adjusted, n = 11), 
           ema23 = TTR::EMA(adjusted, n = 23), 
           sma47 = TTR::SMA(adjusted, n = 47), 
           sma53 = TTR::SMA(adjusted, n = 53), 
           sma199 = TTR::SMA(adjusted, n = 199), 
           perc_abov_ema11 = log(adjusted / ema11), 
           perc_abov_sma199 = log(adjusted / sma199), 

           roll_mean_ema11_200d = mean_roll_200(perc_abov_ema11), 
           roll_sd_ema11_200d = mean_roll_200(perc_abov_ema11),
           sd_abov_ema11 = (ema11 - roll_mean_ema11_200d) / roll_sd_ema11_200d,           
           roll_mean_sma199_1Y = mean_roll_252(perc_abov_sma199), 
           roll_sd_sma199_1Y = mean_roll_252(perc_abov_sma199),
           sd_abov_sma199 = (sma199 - roll_mean_sma199_1Y) / roll_sd_sma199_1Y, 
           
           corr_ema23_sma47_200d = corr_roll_200(ema23, sma47), 
           corr_sma53_sma199_1Y = corr_roll_252(sma53, sma199), 

           sma200_volum = TTR::SMA(volume,  n = 200), 
           perc_abov_volum200 = log(volume / sma200_volum), 
           roll_sd_volum200d_1Y = sd_roll_252(perc_abov_volum200),
           
           roll_sd_ret21d_1Y = sd_roll_252(ret21d), 
           
           
           ret_7w = (lead(adjusted, n = 35) / adjusted) - 1) 
  
  return(df)
  
}

reduce_df <- function(df) { 
  df <- df |> 
    select(date, 
           sd_abov_sma199, sd_abov_ema11, 
           roll_sd_ret21d_1Y, roll_sd_volum200d_1Y, 
           corr_sma53_sma199_1Y, corr_ema23_sma47_200d, 
 
           ret_7w)
}

```

# Modeling 

Using the tidymodel framework with Xgboost. 

```{r}
#| label: modeling
#| message: false
#| warning: false
#| eval: false

ticker <- 'AA'
model_type = "7wClassThirdile"
yop <- glue("xgboost_modelv8_explo3_", model_type, "_", ticker)

## Modeling phase now
df0 <- conform_data(ticker) |> augment_df_fin()
df_model <- reduce_df(df0) |> arrange(date) |> 
  mutate(ord_class = as.factor(ntile(ret_7w, 3))) |> 
  na.omit() 

print(paste0("Dealing now with ", ticker))
print(paste0("The ", model_type, " build on ", ticker, " has ", nrow(df_model), " rows"))

######################################################################
############# SAMPLING FOR CROSS-VALIDATION ##########################
######################################################################
library(rsample)
min_size_training <- 500
number_of_samples <- 50
skippy <- 63
laggy <- 21
# get the size of the df we are using. 
validation_size <- floor(nrow(df_model) * 0.2 / number_of_samples) + 1
training_size <- nrow(df_model) - (skippy * (number_of_samples - 1)) - (laggy + validation_size) - 49

if (training_size < 500) {
  training_size <- min_size_training
  skippy <- floor((nrow(df_model) - validation_size - laggy - min_size_training) / number_of_samples) 
  training_size <- nrow(df_model) - (skippy * (number_of_samples - 1)) - (laggy + validation_size) - 49
}

time_slices <- rolling_origin(df_model, 
                              initial = training_size, assess = validation_size + laggy, 
                              lag = -laggy, skip = skippy, 
                              cumulative = FALSE)
######################################################################

library(recipes)
recipe_base <- recipe(formula = ord_class ~., data = df_model) |> 
  update_role(date, new_role="ID") |>
  step_rm("ret_7w") 

library(parsnip)
library(tune)
library(dials)
library(workflows)
library(yardstick)
model_xgboost <- boost_tree(trees = tune(), mtry = tune(), loss_reduction = tune(), 
                            tree_depth = tune(), 
                            learn_rate = tune(), min_n = tune()) %>% 
  set_engine("xgboost") |>  
  set_mode("classification") 

stopping_grid <-grid_latin_hypercube(trees(range = c(400, 800)), 
                                     loss_reduction(range = c(-10, 1.5)), 
                                     mtry(range = c(12L, 17L)), 
                                     learn_rate(range = c(-4, -2)), 
                                     min_n(range = c(23L, 31L)),   
                                     tree_depth(range = c(5L, 9L)), 
                                     size = 15)

wf <- workflow() |> add_recipe(recipe_base) |> add_model(model_xgboost)  

print("Starting now the resampling process")
doParallel::registerDoParallel()
xgboost_resampling <- tune_grid(wf, time_slices, 
                                grid = stopping_grid, 
                                metrics = metric_set(accuracy, mn_log_loss), 
                                control = control_resamples(save_pred = TRUE, 
                                                            save_workflow = TRUE))
print("resampling process over. Looking now for best model.")

######################################################################
############# ESTABLISHING METRICS  ##################################
######################################################################

yo_soft_acc <- xgboost_resampling |> collect_predictions() |> 
  mutate(soft_acc = case_when(.pred_class=="3" & ord_class == "3" ~ 1, 
                              .pred_class!="3" & ord_class != "3" ~ 1, 
                              TRUE ~ 0)) |> 
  group_by(.config) |> 
  summarize(mean_soft_acc = sum(soft_acc)/n(), 
            mtry = mean(mtry), tree_depth = mean(tree_depth), 
            trees = mean(trees), 
            min_n = mean(min_n), learn_rate = mean(learn_rate))

# if I predict a 3, is it indeed a 3? Higher is better
yo_precision <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(spec_3 = if_else(.pred_class == "3" & ord_class == "3", 1, 0)) %>% 
  filter(.pred_class == "3") %>% 
  group_by(.config) %>% 
  summarize(mean_preci = sum(spec_3)/n())

# if there is a "3" in the actual returns, do I manage to predict it! Higher is better
yo_recall <- xgboost_resampling %>% collect_predictions() |>  
  mutate(sens_3 = if_else(.pred_class == "3" & ord_class == "3", 1, 0)) |> 
  select(-mtry, -min_n, -learn_rate, -loss_reduction, -tree_depth) |> 
  filter(ord_class == "3") |> 
  group_by(.config) |> 
  summarize(mean_recall = sum(sens_3)/n())

# if I predict a 3, is it indeed a 3? Higher is better
yo_soft_preci <- xgboost_resampling |> collect_predictions() |> 
  mutate(spec_3 = case_when(.pred_class=="3" & ord_class == "3" ~ 1, 
                            .pred_class=="3" & ord_class == "2" ~ 0.5, 
                            .pred_class=="3" & ord_class == "1" ~ 0, 
                            TRUE ~ 0)) %>% 
  filter(.pred_class == "3") |>  
  group_by(.config) |> 
  summarize(mean_soft_preci = sum(spec_3)/n())

yo_cost3 <- left_join(yo_precision, yo_recall) %>% left_join(., yo_soft_preci) %>% 
  left_join(., yo_soft_acc) %>% 
  mutate(soft_acc_rank = percent_rank(mean_soft_acc), recall_rank = percent_rank(mean_recall), 
         preci_rank = percent_rank(mean_preci), soft_preci_rank = percent_rank(mean_soft_preci), 
         avg_rank =  0.3 * preci_rank + 0.3 * soft_preci_rank + 0.25 * soft_acc_rank + 0.15 * recall_rank)

yo_metric <- left_join(yo_precision, yo_soft_acc) |> left_join(yo_recall) |> 
  left_join(yo_soft_preci) |> left_join(yo_cost3) |> 
  select(.config, avg_rank, mean_preci, mean_soft_preci, mean_recall, mean_soft_acc, 
         mtry, tree_depth, trees, min_n, learn_rate) |> 
  arrange(desc(avg_rank), mean_preci)

#rm(yo_sens, yo_spec, yo_cost3, yo_acc, yo_log, yo_cost_acc)

write_csv(yo_metric, glue(the_path, "/models/model_metrics/", yop, ".csv"))
######################################################################


best_model <- yo_metric$.config[1]

best_param <-xgboost_resampling |> collect_metrics() |> 
  filter(.config == best_model) |> slice_tail()
best_param

final_model <- finalize_model(model_xgboost, best_param)
final_model

final_wf <- workflow() |> add_recipe(recipe_base) |> add_model(final_model)
final_wf

model_base <- fit(object = final_wf, data = df_model)

write_rds(model_base, glue(the_path, "/models/model_raw/", yop, ".rda"))

library(vip)
df_prep <- prep(recipe_base)
var_importance <- final_model %>% 
  set_engine("xgboost", importance = "permutation") %>% 
  fit(ord_class ~ ., data = juice(df_prep) %>% select(-date)) %>%
  vi()

write_csv(var_importance, 
          glue(the_path, "/models/model_vars_imp/", yop, ".csv"))

rm(df_prep)

```


# Correlation analysis

```{r}
#| message: false
#| warning: false
#| eval: false

# setting up the path within the project for easier portability of code
the_path <- here::here()

library(corrr)
library(glue)
library(dplyr)
library(purrr)
library(tidyr)

source(glue(the_path, "/models/functions/model_v8_3.R"))

model <- 'version_v8_3'
tickers = c('AA', 'AMD', 'AAPL', 'CVX', 'FDX', 'GOOG', 'HAL', 'PYPL', 'SBUX') 
create_cor_df <- function(ticker) { 
  df0 <- model_v82(ticker)
  df <- df0 %>% drop_na()
  df_cor <- df %>% select(-date, -ret_7w) 
  yo <- correlate(df_cor) %>% shave() %>% stretch()
  return(yo)
  }

df0 <- tibble(model = model, ticker = tickers) %>% 
  mutate(cor_df = map(ticker, create_cor_df)) %>% 
  unnest()

df1 <- df0 %>% filter(r >= 0.5 | r <= -0.5) |> 
  arrange(x)

write_csv(df1, 'correlations/model_v8_3.csv')

library(gt)

df1 |> gt()
```


# picking up the important variables 

```{r}
#| message: false
#| warning: false
#| eval: false


```



# Building up the models

Use best variables from 8.2 and 8.3 and checked correlations 

| Var 1.           | Var 2               | corr  | model | imp Var 1 | imp Var 2|
|-------| ------|-------------|-------|-----------|----------|
| roll_sd_ret21d_1Y | roll_sd_volu200_1Y | 0.61  | V1_b   | 1        | 3.4     |    
| roll_sd_ret21d_1Y | roll_sd_volu200_1Y | 0.66  | V8_2   | 1        | 3.5     | 
| roll_sd_ret21d_1Y | roll_sd_volu200_1Y |   | V8_3       | 1.2      |     | 
| sd_abov_sma199  | roll_sd_volu200_1Y   | -0.54 | V8_2   |          |    |
| corr_sma50_sma200_199d | corr_ema20_sma50_1Y | 0.63 | V1_b | 3.4   |  4.2| 








