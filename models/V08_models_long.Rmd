---
title: "V08 - Models"
author: "FdR"
date: "4/28/2022"
output: html_document
---

We are adding more intermarket indicators

The idea is also to have like 20-30 stocks universe (all sectors, all size) and bets on top 2 vs bottom 2 each week.  Or something along these lines

```{r}
library(readr)
library(dplyr)
library(stringr)
library(tidyr)
library(purrr)
library(glue)
library(lubridate)
library(roll)
library(rsample)
library(parsnip)
library(recipes)
library(tune)
library(workflows)
library(dials)
library(yardstick)
library(embed)

ticker <- "AA"
mkt <- "SPY"
sect <- "XME"

the_path <- here::here()

### Function to harmonize the data. 
### ### This is copied from summary_report_v3
conform_data <- function(ticker, interval, provider){
  if (interval == "Daily" & provider == "Yahoo"){
    df <- read_csv(paste0(the_path, "/data_stock_ya/", ticker, ".csv"), show_col_types = FALSE) %>% 
      na.omit()
  } else if (interval == "Daily" & provider == "Tiingo"){
    df <- read_csv(paste0(the_path, "/data_stock_ti/", ticker, ".csv"), show_col_types = FALSE) %>% 
      na.omit() %>% 
      rename(index = date, open = adjOpen, high = adjHigh, low = adjLow, close = adjClose, 
             adjusted = adjClose, volume = adjVolume)    
  } else if (interval == "Daily" & provider == "fmpr"){
    df <- read_csv(paste0(the_path, "/data_stock_fmpr/", ticker, ".csv"), show_col_types = FALSE) %>% 
      rename(index = date, adjusted = adjClose) %>% arrange(index)   
  }
  df <- df %>% arrange(index)
  return(df)
}

get_fmpr_etf_holder <- function(etf) { 
  base_url <- "https://financialmodelingprep.com/api/v3/"
  endpoint <- 'etf-holder/'
  headers = c(`Upgrade-Insecure-Requests` = '1')
  params = list(`datatype` = 'json', 
                `apikey` = "9b274cc7e7560cdb56d931b697c1ed45")
  res <- httr::GET(url = glue(base_url, endpoint, etf), 
                   httr::add_headers(.headers = headers), query = params)
  return_json <- httr::content(res, as = "text")
  d <- jsonlite::fromJSON(return_json) %>% tibble::as_tibble()
  d <- tibble::add_column(d, etf, .before = 1)
  d <- d %>% select(-isin, -cusip, -sharesNumber) %>% arrange(desc(weightPercentage))
  write_csv(d, paste0(the_path, "/analysis/etf/", etf, "_", today(), ".csv"))
  return(d)
}

get_fmpr_prices <- function(ticker, from = "2001-01-02", to = today()) { 
  base_url <- "https://financialmodelingprep.com/api/v3/"
  endpoint <- 'historical-price-full/'
  headers = c(`Upgrade-Insecure-Requests` = '1')
  params = list(`datatype` = 'json', `from` = from, `to` = to, 
                `apikey` = "9b274cc7e7560cdb56d931b697c1ed45")
  res <- httr::GET(url = glue(base_url, endpoint, ticker), 
                   httr::add_headers(.headers = headers), query = params)
  return_json <- httr::content(res, as = "text")
  d <- jsonlite::fromJSON(return_json)
  d <- tibble::as_tibble(d$historical)
  write_csv(d, glue({the_path}, "/data_stock_fmpr/", {ticker}, ".csv"))
}

## function to have percentage in etf above a certain amount.  
create_small_ma_df <- function(ticker) {
  df <- conform_data(ticker, interval = "Daily", provider = "fmpr") %>% 
    filter(is.na(volume) == FALSE) %>% 
    mutate(ema19 = TTR::EMA(adjusted, n = 19), 
           ema37 = TTR::EMA(adjusted, n = 37), 
           sma67 = TTR::SMA(adjusted, n = 67), 
           sma200 = TTR::SMA(adjusted, n = 200), 
           above_ema19 = if_else(adjusted > ema19, 1, 0), 
           above_ema37 = if_else(adjusted > ema37, 1, 0), 
           above_sma67 = if_else(adjusted > sma67, 1, 0), 
           above_sma200 = if_else(adjusted > sma200, 1, 0), 
           volume_sma21 = TTR::SMA(volume, n = 21), 
           volume_above_sma21 = if_else(volume > volume_sma21, 1, 0), 
           roc2 = log(adjusted, lag(adjusted, n = 2)), 
           volat_roc2_23days = roll_sd(roc2, width = 23), 
           volat_roc2_293days = roll_sd(roc2, width = 293), 
           stv_above_ltv = if_else(volat_roc2_23days > volat_roc2_293days, 1, 0)
           ) %>% 
    select(index, above_ema19, above_ema37, above_sma67, above_sma200, volume_above_sma21, 
           stv_above_ltv) 
  return(df)
}

possibly_create_small_ma_df <- possibly(.f = create_small_ma_df, otherwise = NA)

### functions to get etf proportion of ticker above some MA
portion_above_ma <- function(etf){ 
  df_etf <- get_fmpr_etf_holder(etf) %>% 
    select(asset) %>% filter(str_length(asset) <= 4)
  for (i in 1:nrow(df_etf)) { 
    get_fmpr_prices(df_etf$asset[i]) 
    print(paste0("Downloaded ticker ", df_etf$asset[i])) 
  } 
  yo <- df_etf %>% 
    mutate(var_above = map(asset, possibly_create_small_ma_df))
  yo2 <- yo %>% unnest(cols = c(var_above)) %>% 
    group_by(index) %>% 
    summarise(zzmark_perc_above_19ema = sum(above_ema19, na.rm = TRUE) / n(), 
              zzmark_perc_above_37ema = sum(above_ema37, na.rm = TRUE) / n(), 
              zzmark_perc_above_67sma = sum(above_sma67, na.rm = TRUE) / n(), 
              zzmark_perc_above_sma200 = sum(above_sma200, na.rm = TRUE) / n(), 
              zzmark_perc_volume_above_sma21 = sum(volume_above_sma21, na.rm = TRUE) / n(), 
              zzmark_perc_stv_above_ltv = sum(stv_above_ltv, na.rm = TRUE) / n())
  return(yo2)
  }


create_base_fin_df_v8 <- function(df){
  df <- df %>%  
    select(index, open, high, low, close, adjusted, volume) %>% arrange(index) %>% 
    mutate(open = as.numeric(open), high = as.numeric(high), low = as.numeric(low), 
           close = as.numeric(close), adjusted = as.numeric(adjusted), 
           volume = as.numeric(volume)) %>% filter(is.na(volume) == FALSE)

  #for the ADX and atr
  adx <- TTR::ADX(df[,3:5], n = 17) %>% as_tibble() %>% 
    select(dim_adx17 = ADX, meltp_din17 = DIn, dim_dip17 = DIp)          ###YES V2-newish
  df <- bind_cols(df, adx) %>% 
    mutate(meltp_adx_slope5 = dim_adx17 / lag(dim_adx17, 5), 
           dim_dip17_slope5 = dim_dip17 / lag(dim_adx17, 5))
  yo <- TTR::ATR(df[,3:5], n = 13) %>% as_tibble() %>% select(atr13 = atr)    ###YES V2
  df <- bind_cols(df, yo) %>% mutate(dim_atr13 = (atr13 / close)) 
  yo <- TTR::ATR(df[,3:5], n = 19) %>% as_tibble() %>% select(atr19 = atr)    ###YES NEW
  df <- bind_cols(df, yo) %>% mutate(meltp_atr19 = (atr19 / close)) 
  
  # Adding the other variables such a moving averages and relative strength index
  df <- df %>% 
    mutate(roc1 = log(adjusted / lag(adjusted, n = 1)), 
           roc3 = log(adjusted / lag(adjusted, n = 3)), 
           dim_roc3 = log(adjusted / lag(adjusted, n = 3)), 
           roc5 = log(adjusted / lag(adjusted, n = 5)), 
           dim_roc7 = log(adjusted / lag(adjusted, n = 7)), 
           dim_roc11 = log(adjusted / lag(adjusted, n = 11)), 
           dim_roc17 = log(adjusted / lag(adjusted, n = 17)), 
           roc21 = log(adjusted / lag(adjusted, n = 21)), 
           dim_roc31 = log(adjusted / lag(adjusted, n = 31)), 
           dim_roc61 = log(adjusted / lag(adjusted, n = 61)), 
           dim_roc97 = log(adjusted / lag(adjusted, n =97)), 
           dim_roc127 = log(adjusted / lag(adjusted, n =127)), 
           roc126 = log(adjusted / lag(adjusted, n = 126)), 
           dim_roc157 = log(adjusted / lag(adjusted, n = 157)), 
           dim_roc193 = log(adjusted / lag(adjusted, n = 193)), 
           dim_roc223 = log(adjusted / lag(adjusted, n = 223)), 
           ema20 = TTR::EMA(adjusted, 20), 
           ema40 = TTR::EMA(adjusted, 40), 
           sma50 = TTR::SMA(adjusted, 50), 
           sma100 = TTR::SMA(adjusted, 100), 
           sma200 = TTR::SMA(adjusted, 200), 
           
           ema40_slope5 = ema40 / lag(ema40, 5), 
           sma50_perc = log(adjusted / sma50), 
           sma200_perc= log(adjusted / sma200),  
           roll_mean_roc126_126 = roll_mean(roc126, width = 126), 
           roll_mean_roc126_252 = roll_mean(roc126, width = 252), 
           roll_sd_roc126_126 = roll_sd(roc126, width = 126), 
           roll_mean_sma200_1 = roll_mean(sma200_perc, width = 293), 
           roll_sd_sma200_1 = roll_sd(sma200_perc, width = 293), 
           
           std_away_sma200_1 = (sma200_perc - roll_mean_sma200_1) / roll_sd_sma200_1, ###YES V2
           std_away_roc126_126 = (roc126 - roll_mean_roc126_126) / roll_sd_roc126_126,###YES V2Mom    
           corr199_sma50_sma200 = roll_cor(sma50, sma200, width = 199),  ###YES V6
           corr127_ema20_sma50 = roll_cor(ema20, sma50, width = 127),    ###YES
           corr251_ema20_sma50 = roll_cor(ema20, sma50, width = 251),    ###YES V3
           corr63_atr13_atr19 = roll_cor(atr13, atr19, width = 61),      ###YES NEW
           
           roll_sd_sma50_2 = roll_sd(sma50_perc, width = 512), 
           roll_mean_sma50_2 = roll_mean(sma50_perc, width = 252), 
           meltp_diff_sd_sma50_2 = (sma50_perc - roll_mean_sma50_2) / roll_sd_sma50_2,  
           
           
           rsi13 = TTR::RSI(close, 13), 
           rsi19 = TTR::RSI(close, 19), 
           dim_rsi13_slope5 = rsi13 / lag(rsi13, 5), 
           volum_sma47 = TTR::SMA(volume,  n = 47), 
           volum_sma97 = TTR::SMA(volume,  n = 97), 
           volum_sma200 = TTR::SMA(volume,  n = 200), 
           volum200_perc = log(volume / volum_sma200), 
           volum97_perc = log(volume / volum_sma97), 
           
           corr252_rsi19_sma50 = roll_cor(rsi19, sma50, width = 252),   ###YES V3  
           corr127_rsi13_ema40 = roll_cor(rsi13, ema40, width = 127),   ###YES V3-newish 
           volat_volu97_51days = roll_sd(volum200_perc, width = 51),    ###YES V2  
           volat_volu200_21days = roll_sd(volum200_perc, width = 21),   ###YES V2  
           volat_volu200_252days = roll_sd(volum200_perc, width = 252), ###YES V2
           ma_cross_l = sma50 / sma100,                                 ###YES V2
           corr251_volum_sma47_200 = roll_cor(volum_sma47, volum_sma200, width=252), ###YES V3
           
           # percent from high and low
           max_63 = adjusted / roll_max(adjusted, width = 63),          ###YES V2    
           min_63 = adjusted / roll_min(adjusted, width = 63),          ###YES V2 
           min_126 = adjusted / roll_min(adjusted, width = 126),        ###Yes V3
           max_252 = adjusted / roll_max(adjusted, width = 252),        ###YES V2
           min_252 = adjusted / roll_min(adjusted, width = 252),        ###YES V2
           
           # Volatility of returns
           volat_roc1_19days = roll_sd(roc1, width = 19),               ### these 2 var are highly
           volat_roc1_63days = roll_sd(roc1, width=63),                 ### corr.  So new below
           cor_volatroc1_1963days = roll_cor(volat_roc1_19days, volat_roc1_63days, width = 293), 
           volat_roc5_29days = roll_sd(roc5, width = 29),               ###YES V2-Newish
           volat_roc21_252days = roll_sd(roc21, width = 252),           ###YES V2
           
           # forward looking returns                      
           ret_5w = (lead(adjusted, n = 25) / adjusted) - 1)
  
  return(df)
  
}

##########################
## Relative returns df 
relative_returns_v8 <- function(ticker, mkt, sect) { 
  df_ticker <- conform_data(ticker, interval = "Daily", provider = "fmpr") %>% 
    select(index, adjusted) %>% 
    mutate(adjusted_tic = as.numeric(adjusted), 
           roc3_tic = log(adjusted_tic / lag(adjusted_tic, n = 3)), 
           roc5_tic = log(adjusted_tic / lag(adjusted_tic, n = 5)), 
           roc23_tic = log(adjusted_tic / lag(adjusted_tic, n = 23)), 
           volat_roc23_252days = roll_sd(roc23_tic, width = 252)) 
  df_mkt <- conform_data(mkt, interval = "Daily", provider = "fmpr") %>% 
    select(index, adjusted_mkt = adjusted) %>% 
    mutate(roc2_mkt = log(adjusted_mkt / lag(adjusted_mkt, n = 2)),
           roc3_mkt = log(adjusted_mkt / lag(adjusted_mkt, n = 3)),
           roc5_mkt = log(adjusted_mkt / lag(adjusted_mkt, n = 5))) 
  df_sect <- conform_data(sect, interval = "Daily", provider = "fmpr") %>% 
    select(index, adjusted_sect = adjusted) %>% 
    mutate(roc2_sect = log(adjusted_sect / lag(adjusted_sect, n = 2)),
           roc3_sect = log(adjusted_sect / lag(adjusted_sect, n = 3)),
           roc5_sect = log(adjusted_sect / lag(adjusted_sect, n = 5))) 
  
  yo0 <- left_join(df_mkt, df_sect, by = "index") %>% na.omit() %>% 
    mutate(adjusted_ms = adjusted_sect / adjusted_mkt, 
           roc5_ms = log(adjusted_ms / lag(adjusted_ms, 5)), 
           roc11_ms = log(adjusted_ms / lag(adjusted_ms, 11)),
           zzmark_roc23_ms = log(adjusted_ms / lag(adjusted_ms, 23)),   
           zzmark_roc61_ms = log(adjusted_ms / lag(adjusted_ms, 61)),
           zzmark_roc127_ms = log(adjusted_ms / lag(adjusted_ms, 127)),       ###YES
           zzmark_volat251_roc23_ms = roll_sd(zzmark_roc23_ms, width = 252),  ###YES V62
           zzmark_volat251_roc61_ms = roll_sd(zzmark_roc61_ms, width = 251),  ###YES V62
           zzmark_rollcor19_roc2_ms = roll_cor(roc2_mkt, roc2_sect, width=19),###YES
           zzmark_rollcor67_roc5_ms = roll_cor(roc5_mkt, roc5_sect, width=67) ###YES
           ) %>% 
    select(index, zzmark_roc127_ms, zzmark_volat251_roc23_ms, zzmark_volat251_roc61_ms, 
           zzmark_rollcor19_roc2_ms, zzmark_rollcor67_roc5_ms
           )
    
  yo1 <- left_join(df_ticker, df_mkt, by = "index") %>% na.omit() %>% 
    mutate(adj_tm = adjusted_tic / adjusted_mkt, 
           zzmark_roc61_tm = log(adj_tm / lag(adj_tm, 61)),                 
           zzmark_roc127_tm = log(adj_tm / lag(adj_tm, 127)),                 ###YES
           zzmark_volat251_roc61_tm = roll_sd(zzmark_roc61_tm, width = 251),  ###YES V6
           volat251_roc127_tm = roll_sd(zzmark_roc127_tm, width = 251),
           zzmark_rollcor19_roc3_tm = roll_cor(roc3_tic, roc3_mkt, width = 19),###YES
           zzmark_rollcor67_roc5_tm = roll_cor(roc5_tic, roc5_mkt, width = 67),###YES
           rollsd_volatroc_tm = roll_sd(volat_roc23_252days, volat251_roc127_tm, width=252)
           ) %>% 
    select(index, zzmark_roc127_tm, zzmark_volat251_roc61_tm, 
           zzmark_rollcor19_roc3_tm, zzmark_rollcor67_roc5_tm, rollsd_volatroc_tm
           )

  yo2 <- left_join(df_ticker, df_sect, by = "index") %>% na.omit() %>% 
    mutate(adj_ts = adjusted_tic / adjusted_sect, 
           zzmark_roc23_ts = log(adj_ts / lag(adj_ts, 23)),                 
           zzmark_roc61_ts = log(adj_ts / lag(adj_ts, 61)), 
           zzmark_roc127_ts = log(adj_ts / lag(adj_ts, 127)),                ###YES
           zzmark_volat251_roc23_ts = roll_sd(zzmark_roc23_ts, width = 251), ###YES V6
           zzmark_volat251_roc61_ts = roll_sd(zzmark_roc61_ts, width = 251), ###YES V6
           zzmark_rollcor19_roc3_ts = roll_cor(roc3_tic, roc3_sect, width = 19), 
           zzmark_rollcor67_roc5_ts = roll_cor(roc5_tic, roc5_sect, width = 67), 
           rollsd_volatroc_ts = roll_sd(volat_roc23_252days, zzmark_volat251_roc61_ts, width=252)
    ) %>% 
    select(index,  zzmark_roc127_ts, zzmark_volat251_roc23_ts, zzmark_volat251_roc61_ts, 
           zzmark_rollcor19_roc3_ts, zzmark_rollcor67_roc5_ts, rollsd_volatroc_ts
    )
  
  df <- left_join(yo0, yo1) %>% left_join(., yo2)
  
  df_iwd <- conform_data("IWD", interval = "Daily", provider = "fmpr") %>% 
    select(index, adj_iwd = adjusted) 
  df_iwf <- conform_data("IWF", interval = "Daily", provider = "fmpr") %>% 
    select(index, adj_iwf = adjusted)
  df_rus <- left_join(df_iwd, df_iwf) %>% 
    mutate(grow_over_val = adj_iwf / adj_iwd, 
           rus_sma97 = TTR::SMA(grow_over_val, n = 97), 
           rus_sma47 = TTR::SMA(grow_over_val, n = 47), 
           zzmark_ma_cross_rus = rus_sma47 / rus_sma97, 
           zzmark_grow_over_val_roc19 = log(grow_over_val / lag(grow_over_val, 19)), 
           zzmark_grow_over_val_roc67 = log(grow_over_val / lag(grow_over_val, 67)),
           zzmark_grow_over_val_roc127 = log(grow_over_val / lag(grow_over_val, 127))) %>% 
    select(index, zzmark_grow_over_val_roc19, zzmark_grow_over_val_roc67, zzmark_ma_cross_rus, 
           zzmark_grow_over_val_roc127)
  
  df <- left_join(df, df_rus, by = "index")
  
  return(df)
  
}

##########################
## Only consider the variables that we'll be using in the model 
reduce_df_v8 <- function(old){ 
  df <- old %>% 
    select(index, 
           ## Version 2
           volat_volu200_252days, volat_roc21_252days, min_252, max_252, ma_cross_l, 
           volat_volu200_21days, std_away_sma200_1, cor_volatroc1_1963days, volat_roc5_29days,  
           max_63, min_63, std_away_roc126_126, 
           ## Version 3
           corr251_ema20_sma50, corr127_ema20_sma50, min_126, 
           corr252_rsi19_sma50, corr127_rsi13_ema40, corr251_volum_sma47_200, 
           
           # Version 6
           corr199_sma50_sma200, volat_volu97_51days, 
           
           ## New
           corr63_atr13_atr19, rollsd_volatroc_ts, rollsd_volatroc_tm, 
           
           ## bring in the etf
           zzmark_volat251_roc61_ms, zzmark_volat251_roc23_ts, zzmark_volat251_roc61_tm, 
           zzmark_volat251_roc23_ms, zzmark_volat251_roc61_ts, 
           zzmark_roc127_ms, zzmark_roc127_tm, zzmark_roc127_ts, 
           zzmark_rollcor19_roc2_ms, zzmark_rollcor67_roc5_ms, 
           zzmark_rollcor19_roc3_tm, zzmark_rollcor67_roc5_tm, 
           zzmark_rollcor19_roc3_ts,  zzmark_rollcor67_roc5_ts, 
           zzmark_grow_over_val_roc19, zzmark_grow_over_val_roc67, zzmark_grow_over_val_roc127, 
           zzmark_ma_cross_rus, 
           
           dim_atr13, dim_adx17, dim_dip17_slope5, dim_rsi13_slope5, 
           dim_roc3, dim_roc7, dim_roc11, dim_roc17, dim_roc31, dim_roc61, dim_roc97, dim_roc127, 
           dim_roc157, dim_roc193, dim_roc223,  
           
           ret_5w
    )
}


downl = c(ticker, mkt, sect, "IWF", "IWD")
for (i in 1:length(downl)) { 
  get_fmpr_prices(downl[i]) 
  print(paste0("Downloaded ticker ", downl[i])) 
}

## Modeling phase now
model_type = "5wClassThirdile"
df0 <- conform_data(ticker, interval="Daily", provider = "fmpr") %>% 
  create_base_fin_df_v8() 
df1 <- relative_returns_v8(ticker, mkt, sect) 
df2 <- portion_above_ma(sect) 
df_model <- left_join(df0, df1, by = "index") %>% reduce_df_v8(.) %>% 
  left_join(., df2, by = "index") %>% 
  mutate(ord_class = as.factor(ntile(ret_5w, 3))) %>% na.omit() 
rm(df0, df1, df2)

print(paste0("Dealing now with ", ticker))

print(paste0("The ", model_type, " build on ", ticker, " has ", nrow(df_model), " rows"))
  
skip = 24
prediction_advance = 13 + skip #(5 weeks ahead)
starting_percentage = 0.59 
based_sample = floor((nrow(df_model) - (10 * prediction_advance)) * starting_percentage) 
if (based_sample < 2500) { 
  while (based_sample < 2500 & starting_percentage < 0.8) { 
    starting_percentage = starting_percentage + 0.05
    based_sample = floor((nrow(df_model) - (10 * prediction_advance)) * starting_percentage) 
  } 
} 
skippy = floor((nrow(df_model) - prediction_advance - based_sample) / 36) - 1 
time_slices <- rolling_origin(df_model, initial = based_sample, assess = prediction_advance, 
                              lag = -skip, skip = skippy, cumulative = TRUE) %>% 
  mutate(train = map(splits, training), validation = map(splits, testing)) 
print(paste0("First sample has ", based_sample, " rows and training is skipping ", skippy, " rows."))
print(paste0("There are ", nrow(time_slices) ," time slices created.")) 

recipe_base <- recipe(formula = ord_class ~., data = df_model) %>% 
  update_role(index, new_role="ID") %>% 
  step_rm("ret_5w") %>% 
  step_naomit(columns = all_numeric_predictors()) %>% 
  step_normalize(contains("dim_")) %>% 
  step_normalize(contains("zzmark_")) %>% 
  step_pca(contains("dim_"), id = "pca", num_comp = 5) %>% 
  step_umap(contains("zzmark_"), prefix = "umap_zzmar", 
            id="umap_zzmar", num_comp = 7, options=list(verbose = TRUE, n_threads = 5))

model_xgboost <- boost_tree(trees = tune(), mtry = tune(), loss_reduction = tune(), 
                            tree_depth = tune(), 
                            learn_rate = tune(), min_n = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification") 

stopping_grid <-grid_latin_hypercube(trees(range = c(400, 800)), 
                                     loss_reduction(range = c(-10, 1.5)), 
                                     mtry(range = c(12L, 17L)), 
                                     learn_rate(range = c(-4, -2)), 
                                     min_n(range = c(17L, 29L)),   
                                     tree_depth(range = c(6L, 9L)), 
                                     size = 30) 
wf <- workflow() %>% add_recipe(recipe_base) %>% add_model(model_xgboost)  

print("Starting now the resampling process")
doParallel::registerDoParallel()
xgboost_resampling <- tune_grid(wf, time_slices, 
                                grid = stopping_grid, 
                                metrics = metric_set(accuracy, mn_log_loss), 
                                control = control_resamples(save_pred = TRUE, save_workflow = TRUE))

print("resampling process over. Looking now for best model.")

yo_soft_acc <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(soft_acc = case_when(.pred_class=="3" & ord_class == "3" ~ 1, 
                            .pred_class!="3" & ord_class != "3" ~ 1, 
                            TRUE ~ 0)) %>% 
  group_by(.config) %>% 
  summarize(mean_soft_acc = sum(soft_acc)/n(), 
            mtry = mean(mtry), tree_depth = mean(tree_depth), 
            trees = mean(trees), 
            min_n = mean(min_n), learn_rate = mean(learn_rate))

# if I predict a 3, is it indeed a 3? Higher is better
yo_precision <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(spec_3 = if_else(.pred_class == "3" & ord_class == "3", 1, 0)) %>% 
  filter(.pred_class == "3") %>% 
  group_by(.config) %>% 
  summarize(mean_preci = sum(spec_3)/n())

# if there is a "3" in the actual returns, do I manage to predict it! Higher is better
yo_recall <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(sens_3 = if_else(.pred_class == "3" & ord_class == "3", 1, 0)) %>% 
  select(-mtry, -min_n, -learn_rate, -loss_reduction, -tree_depth) %>% 
  filter(ord_class == "3") %>% 
  group_by(.config) %>% 
  summarize(mean_recall = sum(sens_3)/n())

# if I predict a 3, is it indeed a 3? Higher is better
yo_soft_preci <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(spec_3 = case_when(.pred_class=="3" & ord_class == "3" ~ 1, 
                            .pred_class=="3" & ord_class == "2" ~ 0.5, 
                            .pred_class=="3" & ord_class == "1" ~ 0, 
                            TRUE ~ 0)) %>% 
  #select(-mtry, -min_n, -learn_rate, -loss_reduction) %>% 
  filter(.pred_class == "3") %>% 
  group_by(.config) %>% 
  summarize(mean_soft_preci = sum(spec_3)/n())

yo_cost3 <- left_join(yo_precision, yo_recall) %>% left_join(., yo_soft_preci) %>% 
  left_join(., yo_soft_acc) %>% 
  mutate(soft_acc_rank = percent_rank(mean_soft_acc), recall_rank = percent_rank(mean_recall), 
         preci_rank = percent_rank(mean_preci), soft_preci_rank = percent_rank(mean_soft_preci), 
         avg_rank =  0.5 * preci_rank + 0.2 * soft_preci_rank + 0.15 * soft_acc_rank + 0.15 * recall_rank)

yo_metric <- left_join(yo_precision, yo_soft_acc) %>% left_join(., yo_recall) %>% 
  left_join(., yo_soft_preci) %>% left_join(., yo_cost3) %>% 
  select(.config, avg_rank, mean_preci, mean_soft_preci, mean_recall, mean_soft_acc, 
         mtry, tree_depth, trees, min_n, learn_rate) %>% 
  arrange(desc(avg_rank), mean_preci)

rm(yo_sens, yo_spec, yo_cost3, yo_acc, yo_log, yo_cost_acc)

write_csv(yo_metric, 
          paste0(the_path, "/models/models_metrics/xgboost_modelv81_", model_type, "_", ticker, ".csv"))

best_model <- yo_metric$.config[1]

best_param <-xgboost_resampling %>% collect_metrics() %>% 
  filter(.config == best_model) %>% slice_tail()
best_param

final_model <- finalize_model(model_xgboost, best_param)
final_model

final_wf <- workflow() %>% add_recipe(recipe_base) %>% add_model(final_model)
final_wf

model_base <- fit(object = final_wf, data = df_model)
write_rds(model_base, 
          paste0(the_path, "/models/models_raw/xgboost_modelv81_", model_type, "_", ticker, ".rda"))

library(vip)
df_prep <- prep(recipe_base)
var_importance <- final_model %>% 
  set_engine("xgboost", importance = "permutation") %>% 
  fit(ord_class ~ ., data = juice(df_prep) %>% select(-index)) %>%
  vi()
write_csv(var_importance, 
          paste0(the_path, "/models/models_var_imp/xgboost_modelv81_", model_type, "_", ticker, ".csv"))
rm(df_prep)





```

