---
title: "V08 - Models"
author: "FdR"
date: "4/28/2022"
output: html_document
---

A 7 weeks model.  Research phase. 


The idea is also to have like 20-30 stocks universe (all sectors, all size) and bets on top 2 vs bottom 2 each week.  Or something along these lines

```{r}
library(readr)
library(dplyr)
library(stringr)
library(tidyr)
library(purrr)
library(glue)
library(lubridate)
library(roll)
library(rsample)
library(parsnip)
library(recipes)
library(tune)
library(workflows)
library(dials)
library(yardstick)
library(embed)

ticker <- "AA"
mkt <- "SPY"
sect <- "XME"

the_path <- here::here()

### Function to harmonize the data. 
### ### This is copied from summary_report_v3
conform_data <- function(ticker){
    df <- read_csv(paste0(the_path, "/data_stock_fmpr/", ticker, ".csv"), 
                   show_col_types = FALSE) |>  
      rename(index = date, adjusted = adjClose) |> 
      arrange(index)   
    return(df)
}

## Get the price from the fmpr api
get_fmpr_prices <- function(ticker, from = "2001-01-02", to = today()) { 
  base_url <- "https://financialmodelingprep.com/api/v3/"
  endpoint <- 'historical-price-full/'
  headers = c(`Upgrade-Insecure-Requests` = '1')
  params = list(`datatype` = 'json', `from` = from, `to` = to, 
                `apikey` = "9b274cc7e7560cdb56d931b697c1ed45")
  res <- httr::GET(url = glue(base_url, endpoint, ticker), 
                   httr::add_headers(.headers = headers), query = params)
  return_json <- httr::content(res, as = "text")
  d <- jsonlite::fromJSON(return_json)
  d <- tibble::as_tibble(d$historical)
  write_csv(d, glue({the_path}, "/data_stock_fmpr/", {ticker}, ".csv"))
}


create_base_fin_df_v8 <- function(df){
  df <- df |>   
    select(index, open, high, low, close, adjusted, volume) %>% 
    arrange(index) |>  
    mutate(open = as.numeric(open), high = as.numeric(high), low = as.numeric(low), 
           close = as.numeric(close), adjusted = as.numeric(adjusted), 
           volume = as.numeric(volume)) |> 
    filter(is.na(volume) == FALSE) |> 
    filter(index > today() - 252)  # leaving the last year of data for final testing.  
  
  df <- df |> 
    mutate(volum_sma200 = TTR::SMA(volume,  n = 200), 
           volum200_perc = log(volume / volum_sma200), 
           volat_volu200_252days = roll_sd(volum200_perc, width = 252), 
           ret_7w = (lead(adjusted, n = 35) / adjusted) - 1)
}

## Modeling phase now
model_type = "7wClassThirdile"
df0 <- conform_data(ticker) |> 
  create_base_fin_df_v8() |> 
  mutate(ord_class = as.factor(ntile(ret_7w, 3))) 


print(paste0("Dealing now with ", ticker))

print(paste0("The ", model_type, " build on ", ticker, " has ", nrow(df_model), " rows"))
  
skip = 35
prediction_advance = 13 + skip #(5 weeks ahead)
starting_percentage = 0.59 
based_sample = floor((nrow(df_model) - (10 * prediction_advance)) * starting_percentage) 
if (based_sample < 2500) { 
  while (based_sample < 2500 & starting_percentage < 0.8) { 
    starting_percentage = starting_percentage + 0.05
    based_sample = floor((nrow(df_model) - (10 * prediction_advance)) * starting_percentage) 
  } 
} 
skippy = floor((nrow(df_model) - prediction_advance - based_sample) / 36) - 1 
time_slices <- rolling_origin(df_model, initial = based_sample, assess = prediction_advance, 
                              lag = -skip, skip = skippy, cumulative = TRUE) %>% 
  mutate(train = map(splits, training), validation = map(splits, testing)) 
print(paste0("First sample has ", based_sample, " rows and training is skipping ", skippy, " rows."))
print(paste0("There are ", nrow(time_slices) ," time slices created.")) 

recipe_base <- recipe(formula = ord_class ~., data = df_model) %>% 
  update_role(index, new_role="ID") %>% 
  step_rm("ret_5w") %>% 
  step_naomit(columns = all_numeric_predictors()) %>% 
  step_normalize(contains("dim_")) %>% 
  step_normalize(contains("zzmark_")) %>% 
  step_pca(contains("dim_"), id = "pca", num_comp = 5) %>% 
  step_umap(contains("zzmark_"), prefix = "umap_zzmar", 
            id="umap_zzmar", num_comp = 7, options=list(verbose = TRUE, n_threads = 5))

model_xgboost <- boost_tree(trees = tune(), mtry = tune(), loss_reduction = tune(), 
                            tree_depth = tune(), 
                            learn_rate = tune(), min_n = tune()) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification") 

stopping_grid <-grid_latin_hypercube(trees(range = c(400, 800)), 
                                     loss_reduction(range = c(-10, 1.5)), 
                                     mtry(range = c(12L, 17L)), 
                                     learn_rate(range = c(-4, -2)), 
                                     min_n(range = c(17L, 29L)),   
                                     tree_depth(range = c(6L, 9L)), 
                                     size = 30) 
wf <- workflow() %>% add_recipe(recipe_base) %>% add_model(model_xgboost)  

print("Starting now the resampling process")
doParallel::registerDoParallel()
xgboost_resampling <- tune_grid(wf, time_slices, 
                                grid = stopping_grid, 
                                metrics = metric_set(accuracy, mn_log_loss), 
                                control = control_resamples(save_pred = TRUE, save_workflow = TRUE))

print("resampling process over. Looking now for best model.")

yo_soft_acc <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(soft_acc = case_when(.pred_class=="3" & ord_class == "3" ~ 1, 
                            .pred_class!="3" & ord_class != "3" ~ 1, 
                            TRUE ~ 0)) %>% 
  group_by(.config) %>% 
  summarize(mean_soft_acc = sum(soft_acc)/n(), 
            mtry = mean(mtry), tree_depth = mean(tree_depth), 
            trees = mean(trees), 
            min_n = mean(min_n), learn_rate = mean(learn_rate))

# if I predict a 3, is it indeed a 3? Higher is better
yo_precision <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(spec_3 = if_else(.pred_class == "3" & ord_class == "3", 1, 0)) %>% 
  filter(.pred_class == "3") %>% 
  group_by(.config) %>% 
  summarize(mean_preci = sum(spec_3)/n())

# if there is a "3" in the actual returns, do I manage to predict it! Higher is better
yo_recall <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(sens_3 = if_else(.pred_class == "3" & ord_class == "3", 1, 0)) %>% 
  select(-mtry, -min_n, -learn_rate, -loss_reduction, -tree_depth) %>% 
  filter(ord_class == "3") %>% 
  group_by(.config) %>% 
  summarize(mean_recall = sum(sens_3)/n())

# if I predict a 3, is it indeed a 3? Higher is better
yo_soft_preci <- xgboost_resampling %>% collect_predictions() %>% 
  mutate(spec_3 = case_when(.pred_class=="3" & ord_class == "3" ~ 1, 
                            .pred_class=="3" & ord_class == "2" ~ 0.5, 
                            .pred_class=="3" & ord_class == "1" ~ 0, 
                            TRUE ~ 0)) %>% 
  #select(-mtry, -min_n, -learn_rate, -loss_reduction) %>% 
  filter(.pred_class == "3") %>% 
  group_by(.config) %>% 
  summarize(mean_soft_preci = sum(spec_3)/n())

yo_cost3 <- left_join(yo_precision, yo_recall) %>% left_join(., yo_soft_preci) %>% 
  left_join(., yo_soft_acc) %>% 
  mutate(soft_acc_rank = percent_rank(mean_soft_acc), recall_rank = percent_rank(mean_recall), 
         preci_rank = percent_rank(mean_preci), soft_preci_rank = percent_rank(mean_soft_preci), 
         avg_rank =  0.5 * preci_rank + 0.2 * soft_preci_rank + 0.15 * soft_acc_rank + 0.15 * recall_rank)

yo_metric <- left_join(yo_precision, yo_soft_acc) %>% left_join(., yo_recall) %>% 
  left_join(., yo_soft_preci) %>% left_join(., yo_cost3) %>% 
  select(.config, avg_rank, mean_preci, mean_soft_preci, mean_recall, mean_soft_acc, 
         mtry, tree_depth, trees, min_n, learn_rate) %>% 
  arrange(desc(avg_rank), mean_preci)

rm(yo_sens, yo_spec, yo_cost3, yo_acc, yo_log, yo_cost_acc)

write_csv(yo_metric, 
          paste0(the_path, "/models/models_metrics/xgboost_modelv81_", model_type, "_", ticker, ".csv"))

best_model <- yo_metric$.config[1]

best_param <-xgboost_resampling %>% collect_metrics() %>% 
  filter(.config == best_model) %>% slice_tail()
best_param

final_model <- finalize_model(model_xgboost, best_param)
final_model

final_wf <- workflow() %>% add_recipe(recipe_base) %>% add_model(final_model)
final_wf

model_base <- fit(object = final_wf, data = df_model)
write_rds(model_base, 
          paste0(the_path, "/models/models_raw/xgboost_modelv81_", model_type, "_", ticker, ".rda"))

library(vip)
df_prep <- prep(recipe_base)
var_importance <- final_model %>% 
  set_engine("xgboost", importance = "permutation") %>% 
  fit(ord_class ~ ., data = juice(df_prep) %>% select(-index)) %>%
  vi()
write_csv(var_importance, 
          paste0(the_path, "/models/models_var_imp/xgboost_modelv81_", model_type, "_", ticker, ".csv"))
rm(df_prep)





```

